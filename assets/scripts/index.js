"use strict";import{Utils}from"./utils.js?b6a1987596";const state={buffer:{vocal:null,music:null},source:{vocal:null,music:null},volume:{node:{vocal:null,music:null},gain:{vocal:1,music:1}},detail:null,animid:null,onplay:!1,timeAt:0,timeOn:0,peaks:{vocal:null,music:null}},select={at:0,to:0,pt:1,on:!1},UI={document:document.documentElement,fileBtn:Utils.Elem.$("#fileBtn"),saveBtn:Utils.Elem.$("#saveBtn"),playBtn:Utils.Elem.$("#playBtn"),stopBtn:Utils.Elem.$("#stopBtn"),percent:Utils.Elem.$("#percent"),progress:Utils.Elem.$(".progress"),detail:Utils.Elem.$(".detail"),parent:{vocal:Utils.Elem.$("#vocal"),music:Utils.Elem.$("#music")},track:Utils.Elem.$(".track"),graph:Utils.Elem.$(".graph"),wave:{vocal:"#808080",music:"#808080"},mask:{vocal:"#fbbf24",music:"#38bdf8"}};UI.canvas={vocal:UI.parent.vocal.lastElementChild,music:UI.parent.music.lastElementChild},UI.contxt={vocal:UI.canvas.vocal.getContext("2d"),music:UI.canvas.music.getContext("2d")};const getUI=t=>({parent:UI.parent[t],canvas:UI.canvas[t],contxt:UI.contxt[t],wave:UI.wave[t],mask:UI.mask[t]}),worker=new Worker(URL.createObjectURL(new Blob(['importScripts("https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js?b6a1987596"),ort.env.wasm.wasmPaths="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/";const config={fftsize:4096,hopsize:1024,freqbin:1024,timecnt:512,epsilon:1e-10,vocals:null,accomp:null},bitRevTable=new Uint32Array(config.fftsize),hannWindow=new Float32Array(config.fftsize);for(let a,b=0;b<config.fftsize;b++){a=0;for(let c=0;1<<c<config.fftsize;c++)1&b>>c&&(a|=config.fftsize>>c+1);bitRevTable[b]=a,hannWindow[b]=.5*(1-Math.cos(2*Math.PI*b/(config.fftsize-1)))}function fft(a,b){for(let c=0;c<config.fftsize;c++){const d=bitRevTable[c];c<d&&([a[c],a[d]]=[a[d],a[c]],[b[c],b[d]]=[b[d],b[c]])}for(let c=2;c<=config.fftsize;c<<=1){const d=-2*Math.PI/c,e=Math.cos(d),f=Math.sin(d);for(let d=0;d<config.fftsize;d+=c){let g=1,h=0;for(let i=0;i<c/2;i++){const j=a[d+i],k=b[d+i],l=a[d+i+c/2]*g-b[d+i+c/2]*h,m=a[d+i+c/2]*h+b[d+i+c/2]*g;a[d+i]=j+l,b[d+i]=k+m,a[d+i+c/2]=j-l,b[d+i+c/2]=k-m;const n=g*e-h*f;h=g*f+h*e,g=n}}}}function ifft(a,b){for(let c=0;c<config.fftsize;c++)b[c]=-b[c];fft(a,b);for(let c=0;c<config.fftsize;c++)a[c]/=config.fftsize}function performSTFT(a){const b=Math.floor((a.length-config.fftsize)/config.hopsize)+1,c=new Float32Array(b*config.freqbin),d=new Float32Array(b*(config.fftsize/2+1)),e=new Float32Array(config.fftsize),g=new Float32Array(config.fftsize);for(let h=0;h<b;h++){e.fill(0),g.fill(0);for(let b=0;b<config.fftsize;b++)e[b]=a[h*config.hopsize+b]*hannWindow[b];fft(e,g);for(let a=0;a<config.freqbin;a++)c[h*config.freqbin+a]=Math.sqrt(e[a]*e[a]+g[a]*g[a]);for(let a=0;a<=config.fftsize/2;a++)d[h*(config.fftsize/2+1)+a]=Math.atan2(g[a],e[a])}return{magnitudes:c,phases:d,numFrames:b}}function performISTFT(a,b,c){const d=(c-1)*config.hopsize+config.fftsize,e=new Float32Array(d),g=new Float32Array(d),h=new Float32Array(config.fftsize),j=new Float32Array(config.fftsize);for(let d=0;d<c;d++){h.fill(0),j.fill(0);for(let c=0;c<=config.fftsize/2;c++){const e=c<config.freqbin?a[d*config.freqbin+c]:0,f=b[d*(config.fftsize/2+1)+c];h[c]=e*Math.cos(f),j[c]=e*Math.sin(f),0<c&&c<config.fftsize/2&&(h[config.fftsize-c]=h[c],j[config.fftsize-c]=-j[c])}ifft(h,j);for(let a=0;a<config.fftsize;a++){const b=d*config.hopsize+a;e[b]+=h[a]*hannWindow[a],g[b]+=hannWindow[a]*hannWindow[a]}}for(let d=0;d<e.length;d++)1e-10<g[d]&&(e[d]/=g[d]);return e}onmessage=async a=>{const{type:b,payload:c}=a.data;if("LOAD"===b)try{ort.env.logLevel="error",ort.env.wasm.numThreads=navigator.hardwareConcurrency||4;const a={executionProviders:["wasm"],graphOptimizationLevel:"all",logSeverityLevel:3};config.vocals=await ort.InferenceSession.create(c.vocals,a),config.accomp=await ort.InferenceSession.create(c.accomp,a),postMessage({type:"READY"})}catch(a){postMessage({type:"ERROR",error:a.message})}if("PROCESS"===b)try{const{audioData:a}=c;postMessage({type:"PROGRESS",pass:5,text:"Generating spectrogram..."});const b=performSTFT(a[0]),d=performSTFT(a[1]),e=b.numFrames,f=Math.ceil(e/config.timecnt),g=new Float32Array(e*config.freqbin),h=new Float32Array(e*config.freqbin),i=new Float32Array(e*config.freqbin),j=new Float32Array(e*config.freqbin);for(let a=0;a<f;a++){const c=Math.round(10+80*(a/f));postMessage({type:"PROGRESS",pass:c,text:"Processing slices..."});const k=new Float32Array(2*config.timecnt*config.freqbin);for(let c=0;c<config.timecnt;c++){const g=a*config.timecnt+c;if(g>=e)break;for(let a=0;a<config.freqbin;a++)k[0+1024*c+a]=b.magnitudes[1024*g+a],k[524288+1024*c+a]=d.magnitudes[1024*g+a]}const l=new ort.Tensor("float32",k,[2,1,config.timecnt,config.freqbin]),m=await config.vocals.run({x:l}),n=await config.accomp.run({x:l}),o=m.y.data,p=n.y.data;for(let b=0;b<config.timecnt;b++){const c=a*config.timecnt+b;if(c>=e)break;for(let a=0;a<config.freqbin;a++){const d=1024*b+a;g[1024*c+a]=o[0+d],h[1024*c+a]=o[524288+d],i[1024*c+a]=p[0+d],j[1024*c+a]=p[524288+d]}}}postMessage({type:"PROGRESS",pass:90,text:"Reconstructing audio..."});const k=[performISTFT(g,b.phases,e),performISTFT(h,d.phases,e)],l=[performISTFT(i,b.phases,e),performISTFT(j,d.phases,e)];postMessage({type:"DONE",vocals:k,accomp:l})}catch(a){postMessage({type:"ERROR",error:a.message})}};'],{type:"text/javascript"}))),Status={el:Utils.Elem.$("#status-window"),pct:Utils.Elem.$("#floating-percent"),msg:Utils.Elem.$("#floating-infoMsg"),show(t){this.msg.innerText=t,this.pct.classList.remove("hidden"),this.el.classList.add("active")},info(t){this.msg.innerText=t,this.pct.classList.add("hidden"),this.el.classList.add("active")},update(t){this.pct.textContent=t+"%"},error(t){this.msg.innerText=t,this.pct.classList.add("hidden"),this.el.classList.add("active"),setTimeout(()=>this.hide(),5e3)},hide(){this.el.classList.remove("active")}},updateUIProgress=(t,e)=>{Utils.Elem.attr(UI.percent,"data-text",Math.round(t)+"%"),Utils.Elem.attr(UI.progress,"data-text",e)},animatePlayhead=()=>{if(!state.onplay)return;UI.canvas.vocal.getBoundingClientRect();const t=state.timeAt+(Utils.audioContext.currentTime-state.timeOn),e=t/state.buffer.vocal.duration;t>=select.to?stopPlayback():(Utils.drawWaveForm(e,state.peaks.vocal,getUI("vocal")),Utils.drawWaveForm(e,state.peaks.music,getUI("music")),UI.parent.vocal.dataset.time=Utils.FormatTime(t,!0),UI.parent.music.dataset.time=Utils.FormatTime(t,!0),state.animid=requestAnimationFrame(animatePlayhead))},stopPlayback=()=>{if(state.source)try{state.source.vocal.stop(),state.source.vocal=null,state.source.music.stop(),state.source.music=null}catch(t){}cancelAnimationFrame(state.animid),select.at=0,state.animid=null,state.onplay=!1,Utils.drawWaveForm(0,state.peaks.vocal,getUI("vocal")),Utils.drawWaveForm(0,state.peaks.music,getUI("music")),UI.parent.vocal.dataset.time=Utils.FormatTime(state.buffer.vocal.duration,!0),UI.parent.music.dataset.time=Utils.FormatTime(state.buffer.music.duration,!0),Utils.Elem.remClass(UI.playBtn,"hidden"),Utils.Elem.addClass(UI.stopBtn,"hidden")},startPlayback=async()=>{state.buffer&&(state.onplay?stopPlayback():("suspended"===Utils.audioContext.state&&await Utils.audioContext.resume(),state.timeAt=select.at,state.timeOn=Utils.audioContext.currentTime,state.source.vocal=Utils.audioContext.createBufferSource(),state.source.music=Utils.audioContext.createBufferSource(),state.source.vocal.buffer=state.buffer.vocal,state.source.music.buffer=state.buffer.music,state.volume.node.vocal=Utils.audioContext.createGain(),state.volume.node.music=Utils.audioContext.createGain(),state.volume.node.vocal.gain.value=state.volume.gain.vocal,state.volume.node.music.gain.value=state.volume.gain.music,state.source.vocal.connect(state.volume.node.vocal).connect(Utils.audioContext.destination),state.source.music.connect(state.volume.node.music).connect(Utils.audioContext.destination),state.source.onended=()=>{state.onplay&&stopPlayback()},state.source.vocal.start(0,select.at,state.buffer.vocal.duration),state.source.music.start(0,select.at,state.buffer.music.duration),state.onplay=!0,Utils.Elem.addClass(UI.playBtn,"hidden"),Utils.Elem.remClass(UI.stopBtn,"hidden"),animatePlayhead()))},GetBuffer=async(t,e)=>{const s=Utils.audioContext.createBuffer(2,t.length,44100);s.copyToChannel(t,0),s.copyToChannel(e,1);const a=new OfflineAudioContext(2,t.length,44100),i=a.createBufferSource();i.buffer=s;const o=a.createBiquadFilter();o.type="highshelf",o.frequency.setValueAtTime(8e3,0),o.gain.setValueAtTime(3,0);const c=a.createDynamicsCompressor();c.threshold.setValueAtTime(-18,0),c.knee.setValueAtTime(12,0),c.ratio.setValueAtTime(4,0),c.attack.setValueAtTime(.005,0),c.release.setValueAtTime(.2,0);const n=a.createGain();return n.gain.setValueAtTime(1.2,0),i.connect(o),o.connect(c),c.connect(n),n.connect(a.destination),i.start(),await a.startRendering()};Utils.Elem.on(document,"input",async t=>{const e=t.target,s=Utils.getRangeThumb(e),a=parseFloat(e.value)/100,i=e.name;if("vocal"===i||"music"===i){const t=e.parentNode;state.volume.gain[i]=a,state.volume.node[i]?.gain.setTargetAtTime(a,Utils.audioContext.currentTime,.01),t.dataset.value=e.value+"%",t.style.setProperty("--left",s+"px"),e.parentNode.dataset.level=a<=1.2?"safe":a<=1.6?"warning":"danger"}}),Utils.Elem.on(document,"pointerdown",async t=>{if("range"===t.target.type){const e=Utils.getRangeThumb(t.target);t.target.parentNode.style.setProperty("--left",e+"px")}}),Utils.Elem.on(document,"click",async t=>{if(t.target.hasAttribute("data-button")){t.preventDefault(),t.stopPropagation();const e=t.target.dataset.button;if("uploadBtn"===e){const t=Utils.Elem.cE("input",{type:"file"}),e=104857600,s=1200;state.onplay&&stopPlayback(),Utils.Elem.on(t,"input",async t=>{const a=t.target.files[0];if(Utils.audioContext&&a){if(a.size>e)return void Status.error("File too large. Maximum size: 100MB.");const t=await Utils.getAudioType(a);if(!t.type||!t.test)return void Status.error("Not supported file format!");updateUIProgress(0,"Process begins..."),Utils.Elem.addClass(UI.fileBtn,"disabled"),Utils.Elem.remClass(UI.progress,"hidden");let i=await Utils.decodeAudio(a);if(44100!==i.sampleRate){const t=new OfflineAudioContext(i.numberOfChannels,Math.ceil(44100*i.duration),44100),e=t.createBufferSource();e.buffer=i,e.connect(t.destination),e.start(0),i=await t.startRendering()}if(i.duration>s)return Status.error("Audio too long. Maximum length: 20 minutes."),Utils.Elem.remClass(UI.fileBtn,"disabled"),void Utils.Elem.addClass(UI.progress,"hidden");select.at=0,select.to=i.duration,state.detail=a.name,state.buffer.music=i,Utils.Elem.text(UI.detail,state.detail),Utils.Elem.addClass(UI.tracks,"hidden"),worker.postMessage({type:"PROCESS",payload:{audioData:[i.getChannelData(0),i.numberOfChannels>1?i.getChannelData(1):i.getChannelData(0)]}})}}),t.click()}else if("playBtn"===e)state.onplay?stopPlayback():startPlayback();else if("saveVocal"===e){Status.show("Export vocal to file...");const t=await Utils.MP3encode(state.buffer.vocal,t=>Status.update(t));Utils.saveFile(t,Utils.getFileName(state.detail,"vocal_",".mp3")),Status.hide()}else if("saveMusic"===e){Status.update(0),Status.show("Export music to file...");const t=await Utils.MP3encode(state.buffer.music,t=>Status.update(t));Utils.saveFile(t,Utils.getFileName(state.detail,"music_",".mp3")),Status.hide()}else"menuToggle"===e&&t.target.nextElementSibling.classList.toggle("visible")}else if(t.target===UI.parent.vocal||t.target===UI.parent.music){const e=t.target.getBoundingClientRect(),s=Utils.clamp(t.clientX-e.left,0,e.width)/e.width*state.buffer.vocal.duration,a=s/state.buffer.vocal.duration;stopPlayback(),select.at=s,Utils.drawWaveForm(a,state.peaks.vocal,getUI("vocal")),Utils.drawWaveForm(a,state.peaks.music,getUI("music")),UI.parent.vocal.dataset.time=Utils.FormatTime(s,!0),UI.parent.music.dataset.time=Utils.FormatTime(s,!0)}}),Utils.Elem.on(window,"load",async()=>{if(!Cookies.get("consent")){const t=Utils.Elem.cE("div",{class:"cookie-bar"}),e=Utils.Elem.cE("div",{class:"cookie-content"}),s=Utils.Elem.cE("div",{class:"cookie-actions"}),a=Utils.Elem.cE("p"),i=Utils.Elem.cE("a",{class:"btn btn-primary",href:"#"}),o=Utils.Elem.cE("a",{class:"btn btn-secondary",href:"/cookies/"});i.textContent="Accept",o.textContent="Settings",a.textContent="We use cookies to enhance your browsing experience and personalize content. By continuing to use our site, you agree to our use of cookies.",s.appendChild(i),s.appendChild(o),e.appendChild(a),t.appendChild(e),t.appendChild(s),document.body.appendChild(t),Utils.Elem.on(i,"click",e=>{e.preventDefault(),e.stopPropagation(),Cookies.set("consent","created",{expires:7,path:"/"}),document.body.removeChild(t)})}}),(async()=>{const t="https://assets.vocalsplit.app/vocals.fp32",e="https://assets.vocalsplit.app/accomp.fp32",s=await caches.open("model-cache");try{const[a,i]=await Promise.all([s.match(t),s.match(e)]);if(a&&i){const[t,e]=await Promise.all([a.arrayBuffer(),i.arrayBuffer()]);worker.postMessage({type:"LOAD",payload:{vocals:t,accomp:e}},[t,e])}else{const[a,i]=await Promise.all([fetch(t,{mode:"cors",credentials:"omit"}),fetch(e,{mode:"cors",credentials:"omit"})]);if(!a.ok||!i.ok)throw new Error("Model files not found!");await Promise.all([s.put(t,a.clone()),s.put(e,i.clone())]);const[o,c]=await Promise.all([a.arrayBuffer(),i.arrayBuffer()]);worker.postMessage({type:"LOAD",payload:{vocals:o,accomp:c}},[o,c])}}catch(t){Status.error("Error: Model loading failed!")}})(),worker.onmessage=async t=>{const{type:e,pass:s,text:a,vocals:i,accomp:o,error:c}=t.data;switch(e){case"READY":Status.hide(),Utils.Elem.remClass(UI.fileBtn,"disabled");break;case"PROGRESS":updateUIProgress(s,a);break;case"DONE":updateUIProgress(95,"Audio mastering..."),state.buffer.vocal=await GetBuffer(i[0],i[1]),updateUIProgress(97,"Audio mastering..."),state.buffer.music=await GetBuffer(o[0],o[1]);const t=getUI("vocal"),e=getUI("music");state.peaks.vocal=Utils.extractPeaks(state.buffer.vocal,t),state.peaks.music=Utils.extractPeaks(state.buffer.music,e),Utils.drawWaveForm(0,state.peaks.vocal,t),Utils.drawWaveForm(0,state.peaks.music,e),Utils.Elem.addClass(UI.progress,"hidden"),Utils.Elem.remClass(UI.fileBtn,"disabled"),Utils.Elem.remClass(UI.track,"hidden");break;case"ERROR":Status.error(c),Utils.Elem.remClass(UI.fileBtn,"disabled"),Utils.Elem.addClass(UI.progress,"hidden")}};const resizeObserver=new ResizeObserver(t=>{for(let e of t){const{width:t}=e.contentRect,{id:s}=e.target;if(state.buffer[s]&&state.peaks[s]){const t=getUI(s);state.peaks[s]=Utils.extractPeaks(state.buffer[s],t),Utils.drawWaveForm(0,state.peaks[s],t)}}});resizeObserver.observe(UI.parent.vocal),resizeObserver.observe(UI.parent.music),Status.info("Loading stem separation models.");